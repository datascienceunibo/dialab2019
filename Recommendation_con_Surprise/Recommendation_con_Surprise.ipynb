{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Laboratorio: Recommendation con Surprise\n",
    "\n",
    "**Programmazione di Applicazioni Data Intensive**  \n",
    "Laurea in Ingegneria e Scienze Informatiche  \n",
    "DISI - Università di Bologna, Cesena\n",
    "\n",
    "Proff. Gianluca Moro, Roberto Pasolini  \n",
    "`nome.cognome@unibo.it`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recommendation\n",
    "\n",
    "- I sistemi di _recommendation_ sono usati per dare agli utenti di un servizio dei suggerimenti mirati in base ai loro interessi\n",
    "  - suggerire prodotti da acquistare su Amazon\n",
    "  - suggerire film o serie da vedere su Netflix\n",
    "  - suggerire canzoni da ascoltare su Spotify\n",
    "  - ...\n",
    "- I metodi di _collaborative filtering_ forniscono suggerimenti sulla base delle associazioni esistenti tra utenti e oggetti\n",
    "  - ad es. nei metodi basati su similarità, per prevedere il voto che un utente $u$ darebbe ad un oggetto $i$ si fa la media (pesata)\n",
    "    - dei voti dati ad $i$ da utenti che han dato voti simili ad $u$ ad altri oggetti (_user-based_)\n",
    "    - dei voti dati da $u$ ad oggetti che hanno ricevuto voti simili ad $i$ da altri utenti (_item-based_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Surprise\n",
    "\n",
    "- _Surprise_ è una libreria Python per la creazione e la validazione di modelli di recommendation\n",
    "  - definisce strutture per rappresentare i dati su cui addestrare i modelli\n",
    "  - permette di caricare dati da diverse fonti o di utilizzare dataset d'esempio\n",
    "  - implementa diverse tecniche basate su similarità, scomposizione di matrici, ...\n",
    "  - fornisce funzionalità per validare i modelli calcolando comuni metriche di accuratezza, ad es. RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Installazione di Surprise\n",
    "\n",
    "- Seguire le istruzioni che seguono per installare Surprise nei PC di laboratorio\n",
    "  - queste istruzioni sono valide per qualsiasi PC con Anaconda installato\n",
    "- Aprire un prompt dei comandi o terminale\n",
    "  - in Windows: tasto Windows -> `cmd` -> Invio\n",
    "- Creare un ambiente Anaconda con Python e alcune librerie di supporto\n",
    "  - `conda create -n surprise python=3.6 numpy pandas scipy joblib ipykernel`\n",
    "- Attivare l'ambiente appena creato\n",
    "  - Windows: `activate surprise`\n",
    "  - Mac/Linux: `source activate surprise`\n",
    "- Installare Surprise\n",
    "  - `conda install -c conda-forge scikit-surprise`\n",
    "- Aggiungere l'ambiente come kernel in Jupyter\n",
    "  - `python -m ipykernel install --user --name surprise --display-name Surprise`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Uso di Surprise\n",
    "\n",
    "- Se questo file era già aperto in Jupyter, aggiornare la pagina\n",
    "- Dal menù _Kernel_ selezionare _Change kernel_, quindi _Surprise_\n",
    "- Eseguire il seguente import e verificare che non ci siano errori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataset\n",
    "\n",
    "- Un `Dataset` consiste in un insieme di voti, ciascuno dato da un determinato utente ad un determinato oggetto\n",
    "- Utenti e oggetti in un `Dataset` sono rappresentati con identificatori _raw_ arbitrari, spesso numeri o stringhe\n",
    "- Un `Dataset` può essere ottenuto da un file CSV o da un DataFrame pandas (a sua volta ottenibile da diverse fonti)\n",
    "- Surprise permette inoltre di caricare diversi dataset d'esempio di uso comune, scaricati _on demand_ dal Web\n",
    "- Carichiamo ad esempio il dataset _MovieLens-100k_, con 100.000 voti dati da migliaia di utenti a migliaia di film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = surprise.Dataset.load_builtin(\"ml-100k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Trainset\n",
    "\n",
    "- Un `Trainset` contiene le stesse informazioni di un `Dataset` in forma ottimizzata per l'utilizzo da parte degli algoritmi d'apprendimento\n",
    "- $M$ utenti ed $N$ oggetti distinti sono identificati in un `Trainset` da identificatori interni (_inner_), ovvero numeri seriali da 0 a $M-1$ e da 0 a $N-1$\n",
    "- Per creare un `Trainset` con tutti i voti contenuti in un `Dataset`, usare il metodo `build_full_trainset` di quest'ultimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_train = ml_data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Estrarre Informazioni da un Trainset\n",
    "\n",
    "- Da un `Trainset` abbiamo accesso rapido ad informazioni quali il numero di utenti distinti, oggetti distinti e voti complessivi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682, 100000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_train.n_users, ml_train.n_items, ml_train.n_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Possiamo consultare l'elenco dei voti noti di un qualsiasi utente od oggetto dai dizionari `ur` e `ir`\n",
    "  - vanno usati gli ID seriali interni dal `Trainset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 3.0), (528, 4.0), (377, 4.0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# es.: 3 voti dati dall'utente 0\n",
    "ml_train.ur[0][:3]\n",
    "# ogni tupla: (ID oggetto, voto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Possiamo vedere la media globale di tutti i voti dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.52986"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_train.global_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Possiamo usare i metodi `to_inner_uid` e `to_raw_uid` per convertire tra gli ID utenti originali del `Dataset` (_raw_) e gli ID utenti seriali del `Trainset` (_inner_)\n",
    "- Possiamo fare lo stesso per gli ID oggetti con `to_inner_iid` e `to_raw_iid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'196'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_train.to_raw_uid(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_train.to_inner_uid(\"196\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## User-based Collaborative Filtering\n",
    "\n",
    "- Nella recommendation _user-based_, il voto $\\hat{r}_{ui}$ previsto per un oggetto $i$ da parte di un utente $u$ è dato dalla media pesata dei voti dati ad $i$ dai $k$ utenti più simili ad $u$, rappresentati in un insieme $N_i^k(u)$\n",
    "$$ \\hat{r}_{ui} = \\frac{\\sum\\limits_{v \\in N^k_i(u)} \\text{sim}(u, v) \\cdot r_{vi}}{\\sum\\limits_{v \\in N^k_i(u)} \\text{sim}(u, v)} $$\n",
    "- La similarità $\\text{sim}(u,v)$ tra due utenti $u$ e $v$ è misurata dai voti dati ad oggetti recensiti da entrambi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Addestramento di un Modello User-Based\n",
    "\n",
    "- In modo simile a scikit-learn, creiamo dapprima un modello user-based \"vuoto\" impostando eventuali parametri\n",
    "  - impostiamo ad esempio il numero massimo _k_ di utenti vicini da considerare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubr = surprise.KNNBasic(k=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Per addestrare il modello usiamo il metodo `fit` passando il `Trainset`\n",
    "  - su IPython/Jupyter si può usare `%%time` per stampare il tempo necessario all'esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "CPU times: user 501 ms, sys: 13.1 ms, total: 514 ms\n",
      "Wall time: 514 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x7ff4b17d4898>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ubr.fit(ml_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Utilizzare un Modello\n",
    "\n",
    "- Una volta addestrato, il modello può prevedere il rating che un utente darebbe ad un oggetto dati i rispettivi ID \"raw\" (cioè quelli usati nel `Dataset` originale)\n",
    "- Ad esempio, per conoscere il voto predetto per l'oggetto con ID \"242\" dall'utente con ID \"196\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid='196', iid='242', r_ui=None, est=3.949815800366104, details={'actual_k': 117, 'was_impossible': False})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = ubr.predict(\"196\", \"242\")\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Otteniamo un oggetto `Prediction` i cui attributi riepilogano la richiesta (`uid` e `iid`) e forniscono i dati della predizione\n",
    "- Il voto predetto è dato dall'attributo `est`, in questo caso circa 3,9 stelle\n",
    "- I `details` indicano informazioni aggiuntive, in questo caso che il voto è stato predetto sulla base di quelli dati da 117 utenti simili al \"196\"\n",
    "- Possiamo accedere a tutti i dati come attributi dell'oggetto, ad es.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.949815800366104"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Validare un Modello\n",
    "\n",
    "- Per valutare le prestazioni di un modello di recommendation e ricercare il migliore, come per i problemi di regressione, i dati a disposizione devono essere divisi in due set disgiunti\n",
    "  - sul _training set_ viene addestrato il modello\n",
    "  - sul _validation set_ le risposte del modello vengono confrontate con quelle reali\n",
    "- Similmente a scikit-learn, Surprise offre un metodo `train_test_split` per dividere un `Dataset` in training e validation set\n",
    "  - `test_size` e `random_state` funzionano come in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_train, ml_val = surprise.model_selection.train_test_split(ml_data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Il training set `ml_train` è un oggetto della classe `Trainset` vista sopra che stavolta contiene solo il 70\\% dei 100.000 voti del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1638, 70000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_train.n_users, ml_train.n_items, ml_train.n_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Il validation set `ml_val` è costituito invece da un elenco di tuple `(id_utente, id_oggetto, voto)` non incluse nel training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('657', '118', 1.0), ('846', '452', 3.0), ('620', '931', 3.0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_val[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Le tuple contenute sono il restante 30\\% del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ml_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ottenere le Predizioni per il Validation Set\n",
    "\n",
    "- Una volta addestrato il modello sul training set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "CPU times: user 265 ms, sys: 6.79 ms, total: 271 ms\n",
      "Wall time: 273 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ubr = surprise.KNNBasic(k=50)\n",
    "ubr.fit(ml_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ...usando il metodo `test`, possiamo passare l'elenco di tuple usato come validation set per ottenere un elenco di corrispondenti oggetti `Prediction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.31 s, sys: 11 ms, total: 4.32 s\n",
      "Wall time: 4.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_preds = ubr.test(ml_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prediction(uid='657', iid='118', r_ui=1.0, est=3.2159872975510826, details={'actual_k': 50, 'was_impossible': False}),\n",
       " Prediction(uid='846', iid='452', r_ui=3.0, est=2.8217010882489393, details={'actual_k': 46, 'was_impossible': False}),\n",
       " Prediction(uid='620', iid='931', r_ui=3.0, est=2.2736204090846504, details={'actual_k': 42, 'was_impossible': False})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_preds[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ogni oggetto `Prediction` contiene sia il voto predetto (`est`) che quello reale dato dal validation set (`r_ui`)\n",
    "- L'insieme di oggetti può così essere usato per valutare il recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Valutazione dell'Accuratezza\n",
    "\n",
    "- Lo scostamento globale tra voti reali e predetti del validation set può essere misurato in vari modi\n",
    "- Quello più comune è il _Root Mean Squared Error_ (RMSE), in pratica la radice quadrata dell'errore quadratico medio già visto nella regressione\n",
    "$$ \\text{RMSE} = \\sqrt{\\frac{1}{|\\hat{R}|} \\sum_{\\hat{r}_{ui} \\in \\hat{R}}(r_{ui} - \\hat{r}_{ui})^2} $$\n",
    "- Surprise implementa questa ed altre metriche nel modulo `accuracy`, alle quali va passato l'insieme di oggetti `Prediction` ottenuto da `test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9917209225966906"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise.accuracy.rmse(ml_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Il risultato ottenuto può essere confrontato con modelli addestrati con diversi parametri o con altri algoritmi, per cercare quale funzioni meglio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## k-fold Cross-Validation\n",
    "\n",
    "- Per fare in modo che il modello sia testato su tutti i dati, è comune usare la _k-fold cross-validation_\n",
    "  - il dataset è diviso in k sottoinsiemi (_fold_) di pari dimensioni\n",
    "  - ogni fold è usato come validation set su un modello addestrato sull'unione degli altri fold per ottenere una misura di accuratezza (es. RMSE)\n",
    "  - l'accuratezza finale è la media delle misure sui singoli fold\n",
    "- Per effettuare la divisione, Surprise offre una classe `KFold` che da un `Dataset` genera _k_ coppie di `Trainset` e validation set corrispondenti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Ad esempio il seguente codice genera tre suddivisioni e per ciascuna addestra e valida un modello stampando il RMSE risultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9874\n",
      "FOLD 2\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9944\n",
      "FOLD 3\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9940\n",
      "CPU times: user 14.9 s, sys: 56.8 ms, total: 15 s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "splitter = surprise.model_selection.KFold(n_splits=3, random_state=42)\n",
    "for n, (train, val) in enumerate(splitter.split(ml_data)):\n",
    "    print(\"FOLD {}\".format(n+1))\n",
    "    ubr = surprise.KNNBasic(k=50)\n",
    "    ubr.fit(train)\n",
    "    preds = ubr.test(val)\n",
    "    surprise.accuracy.rmse(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Per eseguire rapidamente una k-fold cross validation, si può usare la funzione `cross_validate` specificando:\n",
    "  - il modello (algoritmo e parametri) su cui eseguire la validazione\n",
    "  - il `Dataset` da utilizzare\n",
    "  - parametri opzionali quali numero di fold (`cv`, default 5), misure da calcolare (default RMSE e MAE), ...\n",
    "- La funzione restituisce i risultati in un `dict`, che può essere incapsulato in un frame pandas per comodità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "algo = surprise.KNNBasic(k=50)\n",
    "cv_results = surprise.model_selection.cross_validate(algo, ml_data, cv=5)\n",
    "cv_results = pd.DataFrame(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Possiamo consultare i risultati dei singoli test dal frame, che includono anche i tempi impiegati per addestramento e valutazione..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.984627</td>\n",
       "      <td>0.778647</td>\n",
       "      <td>0.414596</td>\n",
       "      <td>3.252371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.984403</td>\n",
       "      <td>0.780505</td>\n",
       "      <td>0.315290</td>\n",
       "      <td>3.044279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.976203</td>\n",
       "      <td>0.771734</td>\n",
       "      <td>0.319620</td>\n",
       "      <td>3.132861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.981606</td>\n",
       "      <td>0.772728</td>\n",
       "      <td>0.313446</td>\n",
       "      <td>3.075123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.981768</td>\n",
       "      <td>0.776023</td>\n",
       "      <td>0.313927</td>\n",
       "      <td>3.034144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_rmse  test_mae  fit_time  test_time\n",
       "0   0.984627  0.778647  0.414596   3.252371\n",
       "1   0.984403  0.780505  0.315290   3.044279\n",
       "2   0.976203  0.771734  0.319620   3.132861\n",
       "3   0.981606  0.772728  0.313446   3.075123\n",
       "4   0.981768  0.776023  0.313927   3.034144"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ...e usando le funzioni di pandas possiamo calcolare statistiche d'interesse, ad es. il RMSE medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9817214982408036"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.test_rmse.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grid Search\n",
    "\n",
    "- Come i modelli di regressione, anche quelli di recommendation hanno degli iperparametri da impostare che possono influenzarne l'accuratezza\n",
    "  - ad esempio il numero k di vicini nella recommendation user-based\n",
    "- Surprise offre una funzionalità di _grid search_ simile a quella di scikit-learn per testare diversi valori dei parametri\n",
    "- Si definisce una \"griglia\" con i valori possibili dei parametri, ad esempio k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\"k\": [50, 100, 200]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Si crea quindi un modello `GridSearchCV` indicando la classe del modello da addestrare, la griglia dei parametri e il numero di fold di cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = surprise.model_selection.GridSearchCV(surprise.KNNBasic, grid, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Si chiama quindi il metodo `fit` passando il dataset completo con i dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "gs.fit(ml_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Il modello addestrato offre attributi simili alla grid search di scikit-learn\n",
    "- Ad esempio `cv_results` fornisce risultati dettagliati sui parametri testati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_rmse</th>\n",
       "      <th>split1_test_rmse</th>\n",
       "      <th>split2_test_rmse</th>\n",
       "      <th>split3_test_rmse</th>\n",
       "      <th>split4_test_rmse</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "      <th>std_test_rmse</th>\n",
       "      <th>rank_test_rmse</th>\n",
       "      <th>split0_test_mae</th>\n",
       "      <th>split1_test_mae</th>\n",
       "      <th>...</th>\n",
       "      <th>split4_test_mae</th>\n",
       "      <th>mean_test_mae</th>\n",
       "      <th>std_test_mae</th>\n",
       "      <th>rank_test_mae</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_time</th>\n",
       "      <th>std_test_time</th>\n",
       "      <th>params</th>\n",
       "      <th>param_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.980350</td>\n",
       "      <td>0.984918</td>\n",
       "      <td>0.982322</td>\n",
       "      <td>0.973918</td>\n",
       "      <td>0.984043</td>\n",
       "      <td>0.981110</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>1</td>\n",
       "      <td>0.774746</td>\n",
       "      <td>0.779236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777062</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>1</td>\n",
       "      <td>0.309208</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>3.196229</td>\n",
       "      <td>0.071187</td>\n",
       "      <td>{'k': 50}</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.992046</td>\n",
       "      <td>0.996194</td>\n",
       "      <td>0.992895</td>\n",
       "      <td>0.985554</td>\n",
       "      <td>0.994411</td>\n",
       "      <td>0.992220</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>2</td>\n",
       "      <td>0.785767</td>\n",
       "      <td>0.789788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786961</td>\n",
       "      <td>0.786002</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>2</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.057372</td>\n",
       "      <td>3.776299</td>\n",
       "      <td>0.090574</td>\n",
       "      <td>{'k': 100}</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.002007</td>\n",
       "      <td>1.006249</td>\n",
       "      <td>1.002672</td>\n",
       "      <td>0.995517</td>\n",
       "      <td>1.004818</td>\n",
       "      <td>1.002253</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>3</td>\n",
       "      <td>0.795665</td>\n",
       "      <td>0.800129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797001</td>\n",
       "      <td>0.796047</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>3</td>\n",
       "      <td>0.301712</td>\n",
       "      <td>0.009867</td>\n",
       "      <td>4.033393</td>\n",
       "      <td>0.151193</td>\n",
       "      <td>{'k': 200}</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   split0_test_rmse  split1_test_rmse  split2_test_rmse  split3_test_rmse  \\\n",
       "0          0.980350          0.984918          0.982322          0.973918   \n",
       "1          0.992046          0.996194          0.992895          0.985554   \n",
       "2          1.002007          1.006249          1.002672          0.995517   \n",
       "\n",
       "   split4_test_rmse  mean_test_rmse  std_test_rmse  rank_test_rmse  \\\n",
       "0          0.984043        0.981110       0.003921               1   \n",
       "1          0.994411        0.992220       0.003620               2   \n",
       "2          1.004818        1.002253       0.003692               3   \n",
       "\n",
       "   split0_test_mae  split1_test_mae  ...  split4_test_mae  mean_test_mae  \\\n",
       "0         0.774746         0.779236  ...         0.777062       0.775510   \n",
       "1         0.785767         0.789788  ...         0.786961       0.786002   \n",
       "2         0.795665         0.800129  ...         0.797001       0.796047   \n",
       "\n",
       "   std_test_mae  rank_test_mae  mean_fit_time  std_fit_time  mean_test_time  \\\n",
       "0      0.002954              1       0.309208      0.007968        3.196229   \n",
       "1      0.002780              2       0.339286      0.057372        3.776299   \n",
       "2      0.002928              3       0.301712      0.009867        4.033393   \n",
       "\n",
       "   std_test_time      params  param_k  \n",
       "0       0.071187   {'k': 50}       50  \n",
       "1       0.090574  {'k': 100}      100  \n",
       "2       0.151193  {'k': 200}      200  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Item-Based Collaborative Filtering\n",
    "\n",
    "- La classe `KNNBasic` può essere usata anche per eseguire recommendation item-based, metodo duale allo user-based\n",
    "- Il voto $\\hat{r}_{ui}$ previsto per un oggetto $i$ da parte di un utente $u$ è dato dalla media pesata dei voti dati da $u$ ai $k$ oggetti più simili ad $i$, rappresentati in un insieme $N_u^k(i)$\n",
    "$$ \\hat{r}_{ui} = \\frac{\\sum\\limits_{j \\in N^k_u(i)} \\text{sim}(i, j) \\cdot r_{uj}}{\\sum\\limits_{j \\in N^k_u(j)} \\text{sim}(i, j)} $$\n",
    "- La similarità $\\text{sim}(i,j)$ tra due oggetti $i$ e $j$ è misurata dai voti ricevuti da utenti che hanno recensito entrambi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Per eseguire item-based recommendation al posto di user-based, cambiamo le opzioni per il calcolo della similarità in questo modo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "CPU times: user 364 ms, sys: 36.4 ms, total: 400 ms\n",
      "Wall time: 400 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ibr = surprise.KNNBasic(k=50, sim_options={\"user_based\": False})\n",
    "ibr.fit(ml_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9838\n",
      "CPU times: user 5.37 s, sys: 3.38 ms, total: 5.37 s\n",
      "Wall time: 5.42 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9837649345323103"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "surprise.accuracy.rmse(ibr.test(ml_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Collaborative Filtering con Fattorizzazione di Matrici\n",
    "\n",
    "- I metodi basati su fattorizzazione o scomposizione di matrici funzionano rappresentando utenti ed oggetti come combinazione di fattori\n",
    "  - i fattori sono ricavati statisticamente dai dati e corrispondono a grandi linee a categorie di oggetti (es. per i film: azione, commedia, ...)\n",
    "  - ciascun oggetto è rappresentato da un vettore col peso di ciascun fattore su di esso (es. quanto un film è d'azione)\n",
    "  - il vettore di ciascun utente indica l'affinità a ciascun fattore (es. quanto gli piacciono i film d'azione)\n",
    "  - il voto stimato è quindi proporzionale alla similarità tra il vettore dell'utente e quello del prodotto\n",
    "- Il modello di questo tipo più semplice è `SVD`\n",
    "  - il parametro principale è il numero di fattori da individuare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- L'algoritmo ha una componente di casualità (la discesa gradiente stocastica), per ottenere risultati riproducibili è necessario impostare il seed tramite NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.42 s, sys: 40 µs, total: 3.42 s\n",
      "Wall time: 3.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fbr = surprise.SVD(n_factors=100)\n",
    "fbr.fit(ml_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9432933101147625"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise.accuracy.rmse(fbr.test(ml_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recommendation Casuale\n",
    "\n",
    "- Surprise offre anche un recommender che prevede voti casuali, utilizzabile come baseline nella valutazione degli altri metodi\n",
    "  - i voti predetti hanno una distribuzione normale con media e varianza calcolate dal training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 86.1 ms, sys: 0 ns, total: 86.1 ms\n",
      "Wall time: 85.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rr = surprise.NormalPredictor()\n",
    "rr.fit(ml_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.5133\n",
      "CPU times: user 290 ms, sys: 9.93 ms, total: 300 ms\n",
      "Wall time: 298 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.5132517686640503"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "surprise.accuracy.rmse(rr.test(ml_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Estraendo i voti a caso ad ogni chiamata, la valutazione eseguita più volte da risultati diversi (se non si imposta un seed)\n",
    "- Ovviamente questo metodo è molto veloce ma ha un RMSE molto più alto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recommendation su Dati Amazon\n",
    "\n",
    "- Nelle prime esercitazioni avevamo visto un metodo di recommendation semplice applicato su dati di vendite estratti da Amazon\n",
    "  - i dati riguardavano solamente i prodotti acquistati dai clienti, senza considerare i voti\n",
    "- Riprendiamo ora gli stessi dati, ma includendo l'informazione sui voti dati dai clienti\n",
    "- I dati sono divisi in due file CSV\n",
    "  - uno contenente gli acquisti fino alla fine del 2000, da usare come training set\n",
    "  - uno contenente gli acquisti dal 2001 in poi, da usare come validation set\n",
    "- Scarichiamo i due file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from urllib.request import urlretrieve\n",
    "if not os.path.exists(\"amazon_train.csv\"):\n",
    "    urlretrieve(\"https://bit.ly/2LdmgTR\", \"amazon_train.csv\")\n",
    "if not os.path.exists(\"amazon_val.csv\"):\n",
    "    urlretrieve(\"https://bit.ly/2IPlyxO\", \"amazon_val.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Per prima cosa, creiamo un `Reader` impostando le caratteristiche dei file\n",
    "  - scala dei voti da 1 a 5\n",
    "  - virgola come separatore di campo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = surprise.Reader(rating_scale=(1, 5), sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Leggiamo i due file in forma di `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_train_data = surprise.Dataset.load_from_file(\"amazon_train.csv\", reader)\n",
    "amazon_val_data = surprise.Dataset.load_from_file(\"amazon_val.csv\", reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Il primo va usato come training set, lo convertiamo quindi in oggetto `Trainset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_train = amazon_train_data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nelle prime esercitazioni il file di training conteneva 9.683 acquisti di 3.384 prodotti distinti eseguiti da 178 prodotti distinti: verifichiamo che i numeri combacino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 3384, 9683)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_train.n_users, amazon_train.n_items, amazon_train.n_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Il secondo va invece convertito in una lista di tuple `(utente, oggetto, voto)` in questo modo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_val = amazon_val_data.build_full_trainset().build_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Il dataset contiene nomi di utenti e film, come possiamo vedere ad esempio dai primi 10 del validation set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[1092996] Reviewer', '[4742] Nights of Cabiria [VHS]', 5.0),\n",
       " ('[1092996] Reviewer', '[50377] The Quiet Man [VHS]', 5.0),\n",
       " ('[1092996] Reviewer', '[51373] Home Alone 2 - Lost in New York [VHS]', 3.0),\n",
       " ('[1092996] Reviewer', '[96217] Dirty Harry [VHS]', 5.0),\n",
       " ('[1092996] Reviewer', '[57410] The Minus Man [VHS]', 3.0),\n",
       " ('[1092996] Reviewer', '[56285] Price Above Rubies [VHS]', 4.0),\n",
       " ('[1092996] Reviewer', '[5099] Brokedown Palace', 3.0),\n",
       " ('[1092996] Reviewer', '[42969] Stripes', 5.0),\n",
       " ('[1092996] Reviewer', '[96764] A Few Good Men [VHS]', 5.0),\n",
       " ('[1092996] Reviewer', '[96502] West Side Story [VHS]', 5.0)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_val[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Il numero di ulteriori voti contenuti in questo set è:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5871"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(amazon_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esercizi\n",
    "\n",
    "Utilizzando `amazon_train` come training set e `amazon_val` come validation set\n",
    "\n",
    "1. Calcolare il RMSE di un recommender casuale\n",
    "2. Calcolare il RMSE di uno user-based recommender con k=50\n",
    "3. Usando un recommender SVD, individuare per quale numero di fattori incluso in 2, 4, 6, ..., 20 si ottiene il miglior RMSE\n",
    "  - usare un ciclo for o una list comprehension\n",
    "  - fissare uno stesso seed prima dell'addestramento di ciascun modello\n",
    "4. Usando SVD con gli stessi numeri possibili di fattori, eseguire una grid search sul dataset `amazon_train_data`\n",
    "5. Usando il recommender al punto 2, stampare i nomi dei 10 film con voto stimato più alto da suggerire all'utente con ID 0 nel `Trainset`\n",
    "  - per semplicità, non è necessario escludere film già valutati"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Surprise",
   "language": "python",
   "name": "surprise"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
